{
  "metadata" : {
    "name" : "Follow them all",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : [ "import scala.concurrent._", "import scala.concurrent.ExecutionContext.Implicits.global" ],
    "customArgs" : null,
    "customSparkConf" : {
      "spark.scheduler.mode" : "FAIR"
    }
  },
  "cells" : [ {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "# Check several jobs under FAIR scheduler condition"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Using Fair scheduler to schedule more than one job's tasks at a given time."
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Setup"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "We create a dummy dataset"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val rdd = sparkContext.parallelize(1 to 10000)",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Parallel jobs (using `Future`)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "Future{ rdd.mapPartitions{ x => Thread.sleep(scala.util.Random.nextInt(10000)); x}.count }",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "Future{ \n  rdd.mapPartitions{ x => Thread.sleep(scala.util.Random.nextInt(10000)); x}\n   .count\n}",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "Future{ \n  rdd.repartition(12).mapPartitions{ x => Thread.sleep(scala.util.Random.nextInt(10000)); x}\n   .count\n}",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}
